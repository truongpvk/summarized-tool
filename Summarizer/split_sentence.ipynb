{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d0c3748-5a0c-4d69-b66e-c5b8a6bf584e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langcodes\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: setuptools in d:\\codespace-learning\\learning_school\\mlforld\\summarizetool\\venv\\lib\\site-packages (from marisa-trie>=1.1.0->language-data>=1.2->langcodes) (80.9.0)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.4 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.4/5.4 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.2/5.4 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Installing collected packages: marisa-trie, language-data, langcodes\n",
      "\n",
      "   ------------- -------------------------- 1/3 [language-data]\n",
      "   ------------- -------------------------- 1/3 [language-data]\n",
      "   ------------- -------------------------- 1/3 [language-data]\n",
      "   ------------- -------------------------- 1/3 [language-data]\n",
      "   ------------- -------------------------- 1/3 [language-data]\n",
      "   -------------------------- ------------- 2/3 [langcodes]\n",
      "   -------------------------- ------------- 2/3 [langcodes]\n",
      "   ---------------------------------------- 3/3 [langcodes]\n",
      "\n",
      "Successfully installed langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langcodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eab84fa6-9f26-49ae-9a59-aacb0461f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "import nltk\n",
    "import re\n",
    "import langcodes\n",
    "nltk.download('punkt_tab', quiet=True, download_dir=\"../venv/nltk_data\")\n",
    "nltk.data.path.append(\"../venv/nltk_data\")\n",
    "\n",
    "def code_to_language_name(code: str) -> str:\n",
    "    try:\n",
    "        return langcodes.get(code).display_name().lower()\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f3f987d2-4db7-4ee0-98da-03ca7d3ac9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(text):\n",
    "    try:\n",
    "        lang = detect(text)[:2]\n",
    "    except:\n",
    "        return [text]\n",
    "\n",
    "    if lang in [\n",
    "        'cs',\n",
    "        'nl',\n",
    "        'en',\n",
    "        'fr', \n",
    "        'de',\n",
    "        'it',\n",
    "        'pt',\n",
    "        'ru',\n",
    "        'es',\n",
    "        'tr',\n",
    "    ]:\n",
    "        return nltk.sent_tokenize(text, language=code_to_language_name(lang))\n",
    "\n",
    "    elif lang == 'vi':\n",
    "        return [s.strip() for s in text.replace(\"!\", \".\").replace(\"?\", \".\").split(\".\") if s.strip()]\n",
    "\n",
    "    elif lang == 'zh': # Chinese\n",
    "        import re\n",
    "        return re.split(r'(。|！|\\!|\\.|？|\\?)', text)\n",
    "\n",
    "    elif lang == 'ar': # Arabic\n",
    "        return [s.strip() for s in text.replace(\"؟\", \".\").replace(\"!\", \".\").split(\".\") if s.strip()]\n",
    "\n",
    "    else: # Defautl\n",
    "        return [s.strip() for s in text.replace(\"!\", \".\").replace(\"?\", \".\").split(\".\") if s.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dcda3f8-7563-4229-8d4a-83b8e2c2bc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When learning how to solve a Rubik’s cube, it ...</td>\n",
       "      <td>Solve a cube from many different sides rather ...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Die richtige Methode anzuwenden, um ein Baby z...</td>\n",
       "      <td>Merke dir das Akronym BACK. Vermeide den „Haus...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>يتيح كل موقع من مواقع التواصل الاجتماعي خيارات...</td>\n",
       "      <td>احذفه أو الغِ صداقته أو متابعته على مواقع التو...</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>如果你的礼物接收者居住在寒冷的地方这将留给他一个持久的回忆并且很实用。如果不知道如何织，可以...</td>\n",
       "      <td>织一条毛绒绒暖和的围巾。 个性化的衣服。 给猫或马缝一件衣服。</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Utiliza una base de cobertura ligera que luzca...</td>\n",
       "      <td>Utiliza base de maquillaje con moderación. Enf...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  When learning how to solve a Rubik’s cube, it ...   \n",
       "1  Die richtige Methode anzuwenden, um ein Baby z...   \n",
       "2  يتيح كل موقع من مواقع التواصل الاجتماعي خيارات...   \n",
       "3  如果你的礼物接收者居住在寒冷的地方这将留给他一个持久的回忆并且很实用。如果不知道如何织，可以...   \n",
       "4  Utiliza una base de cobertura ligera que luzca...   \n",
       "\n",
       "                                             summary   source  \n",
       "0  Solve a cube from many different sides rather ...  English  \n",
       "1  Merke dir das Akronym BACK. Vermeide den „Haus...   German  \n",
       "2  احذفه أو الغِ صداقته أو متابعته على مواقع التو...   Arabic  \n",
       "3                    织一条毛绒绒暖和的围巾。 个性化的衣服。 给猫或马缝一件衣服。  Chinese  \n",
       "4  Utiliza base de maquillaje con moderación. Enf...  Spanish  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(os.path.join(\"..\", \"Dataset\", \"abstractive\", \"abstractive.pk\"), \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "df = data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4775cd65-c441-4fb4-b5e8-56f42889626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['Indonesian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb721798-c34f-4f63-b729-77d5c6c97ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic',\n",
       " 'Chinese',\n",
       " 'Czech',\n",
       " 'Dutch',\n",
       " 'English',\n",
       " 'French',\n",
       " 'German',\n",
       " 'Italian',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Spanish',\n",
       " 'Turkish',\n",
       " 'Vietnamese']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54e9c7b4-3a3d-436e-9367-a66815170172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic',\n",
       " 'Chinese',\n",
       " 'Czech',\n",
       " 'Dutch',\n",
       " 'English',\n",
       " 'French',\n",
       " 'German',\n",
       " 'Italian',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Spanish',\n",
       " 'Turkish',\n",
       " 'Vietnamese']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sentences = dict()\n",
    "for key, value in dataset.items():\n",
    "    dataset_sentences[key] = value.map(split_sentence)\n",
    "\n",
    "list(dataset_sentences.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9d833d02-6362-40ea-a1fa-d3541a1b0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Dataset/extractive/extractive.pk\", \"wb\") as f:\n",
    "    pickle.dump(dataset_sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342094b-2d5e-4a5e-9f2c-0941cadcbc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
